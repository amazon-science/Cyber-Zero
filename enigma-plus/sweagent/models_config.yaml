# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.  

# SPDX-License-Identifier: CC-BY-NC-4.0


#
# Model configurations for EnIGMA+
# Pricing is optional - defaults to 0.0 if not specified (suitable for turn-based evaluation)

openai_models:
  # GPT-3.5 Models
  gpt-3.5-turbo-0125:
    max_context: 16385
    cost_per_input_token: 5e-07
    cost_per_output_token: 1.5e-06
  gpt-3.5-turbo-1106:
    max_context: 16385
    cost_per_input_token: 1.5e-06
    cost_per_output_token: 2e-06
  gpt-3.5-turbo-16k-0613:
    max_context: 16385
    cost_per_input_token: 1.5e-06
    cost_per_output_token: 2e-06

  # GPT-4 Models
  gpt-4-32k-0613:
    max_context: 32768
    cost_per_input_token: 6e-05
    cost_per_output_token: 0.00012
  gpt-4-0613:
    max_context: 8192
    cost_per_input_token: 3e-05
    cost_per_output_token: 6e-05
  gpt-4-1106-preview:
    max_context: 128000
    cost_per_input_token: 1e-05
    cost_per_output_token: 3e-05
  gpt-4-0125-preview:
    max_context: 128000
    cost_per_input_token: 1e-05
    cost_per_output_token: 3e-05
  gpt-4-turbo-2024-04-09:
    max_context: 128000
    cost_per_input_token: 1e-05
    cost_per_output_token: 3e-05
  gpt-4o-2024-05-13:
    max_context: 128000
    cost_per_input_token: 5e-06
    cost_per_output_token: 15e-06
  gpt-4o-mini-2024-07-18:
    max_context: 128000
    cost_per_input_token: 1.5e-07
    cost_per_output_token: 6e-07

  # O1 Models
  o1-preview-2024-09-12:
    max_context: 128000
    cost_per_input_token: 15e-06
    cost_per_output_token: 60e-06
  o1-mini-2024-09-12:
    max_context: 128000
    cost_per_input_token: 3e-6
    cost_per_output_token: 12e-6

  # DeepSeek Models (free/local)
  deepseek-reasoner:
    max_context: 128000
    # No cost specified - defaults to 0.0

  # Local/Custom Models (no pricing)
  "Qwen/Qwen3-8B":
    max_context: 128000
  "Qwen/Qwen3-14B":
    max_context: 128000
  "Qwen/Qwen3-32B":
    max_context: 128000
  "SWE-bench/SWE-agent-LM-7B":
    max_context: 128000
  "SWE-bench/SWE-agent-LM-13B":
    max_context: 128000

# Model shortcuts for easier reference
openai_shortcuts:
  gpt3: gpt-3.5-turbo-1106
  gpt3-legacy: gpt-3.5-turbo-16k-0613
  gpt4: gpt-4-1106-preview
  gpt4-legacy: gpt-4-0613
  gpt4-0125: gpt-4-0125-preview
  gpt3-0125: gpt-3.5-turbo-0125
  gpt4-turbo: gpt-4-turbo-2024-04-09
  gpt4o: gpt-4o-2024-05-13
  gpt-4o-mini: gpt-4o-mini-2024-07-18
  gpt4omini: gpt-4o-mini-2024-07-18
  o1: o1-preview-2024-09-12
  o1-mini: o1-mini-2024-09-12
  swe-agent-lm-7b: "SWE-bench/SWE-agent-LM-7B"
  swe-agent-lm-13b: "SWE-bench/SWE-agent-LM-13B"

anthropic_models:
  claude-instant:
    max_context: 100000
    cost_per_input_token: 1.63e-06
    cost_per_output_token: 5.51e-06
  claude-2.0:
    max_context: 100000
    cost_per_input_token: 1.102e-05
    cost_per_output_token: 3.268e-05
  claude-2.1:
    max_context: 100000
    cost_per_input_token: 1.102e-05
    cost_per_output_token: 3.268e-05
  claude-3-opus-20240229:
    max_context: 200000
    max_tokens: 4096
    cost_per_input_token: 1.5e-05
    cost_per_output_token: 7.5e-05
  claude-3-sonnet-20240229:
    max_context: 200000
    max_tokens: 4096
    cost_per_input_token: 3e-06
    cost_per_output_token: 1.5e-05
  claude-3-5-sonnet-20240620:
    max_context: 200000
    max_tokens: 4096
    cost_per_input_token: 3e-06
    cost_per_output_token: 1.5e-05
  claude-3-haiku-20240307:
    max_context: 200000
    max_tokens: 4096
    cost_per_input_token: 2.5e-07
    cost_per_output_token: 1.25e-06

anthropic_shortcuts:
  claude-2: claude-2.1
  claude-opus: claude-3-opus-20240229
  claude-sonnet: claude-3-sonnet-20240229
  claude-haiku: claude-3-haiku-20240307
  claude-sonnet-3.5: claude-3-5-sonnet-20240620

bedrock_models:
  us.anthropic.claude-3-5-sonnet-20241022-v2:0:
    max_context: 200000
    max_tokens: 4096
    cost_per_input_token: 3e-06
    cost_per_output_token: 15e-06
  us.anthropic.claude-3-7-sonnet-20250219-v1:0:
    max_context: 200000
    max_tokens: 4096
    cost_per_input_token: 3e-06
    cost_per_output_token: 15e-06
  us.anthropic.claude-sonnet-4-20250514-v1:0:
    max_context: 200000
    max_tokens: 4096
    cost_per_input_token: 3e-06
    cost_per_output_token: 15e-06

groq_models:
  llama3-8b-8192:
    max_context: 8192
    cost_per_input_token: 5e-08
    cost_per_output_token: 8e-08
  llama3-70b-8192:
    max_context: 8192
    cost_per_input_token: 5.9e-07
    cost_per_output_token: 7.9e-07
  llama-guard-3-8b:
    max_context: 8192
    # Free model
  llama-3.1-8b-instant:
    max_context: 131072
    # Free model
  llama-3.1-70b-versatile:
    max_context: 131072
    # Free model
  gemma2-9b-it:
    max_context: 8192
    cost_per_input_token: 2e-07
    cost_per_output_token: 2e-07
  gemma-7b-it:
    max_context: 8192
    cost_per_input_token: 5e-08
    cost_per_output_token: 5e-08
  mixtral-8x7b-32768:
    max_context: 32768
    cost_per_input_token: 2.4e-07
    cost_per_output_token: 2.8e-07

groq_shortcuts:
  groq/llama8: llama3-8b-8192
  groq/llama70: llama3-70b-8192
  groq/llamaguard8: llama-guard-3-8b
  groq/llamainstant8: llama-3.1-8b-instant
  groq/llamaversatile70: llama-3.1-70b-versatile
  groq/gemma9it: gemma2-9b-it
  groq/gemma7it: gemma-7b-it
  groq/mixtral8x7: mixtral-8x7b-32768

deepseek_models:
  deepseek-coder:
    max_context: 32000
    cost_per_input_token: 1.4e-07
    cost_per_output_token: 2.8e-07

together_models:
  meta-llama/Llama-2-13b-chat-hf:
    max_context: 4096
    cost_per_input_token: 2.25e-07
    cost_per_output_token: 2.25e-07
  meta-llama/Llama-2-70b-chat-hf:
    max_context: 4096
    cost_per_input_token: 9e-07
    cost_per_output_token: 9e-07
  mistralai/Mistral-7B-Instruct-v0.2:
    max_context: 32768
    cost_per_input_token: 2e-07
    cost_per_output_token: 2e-07
  togethercomputer/RedPajama-INCITE-7B-Chat:
    max_context: 2048
    cost_per_input_token: 2e-07
    cost_per_output_token: 2e-07
  mistralai/Mixtral-8x7B-Instruct-v0.1:
    max_context: 32768
    cost_per_input_token: 6e-07
    cost_per_output_token: 6e-07

together_shortcuts:
  llama13b: meta-llama/Llama-2-13b-chat-hf
  llama70b: meta-llama/Llama-2-70b-chat-hf
  mistral7b: mistralai/Mistral-7B-Instruct-v0.2
  mixtral8x7b: mistralai/Mixtral-8x7B-Instruct-v0.1
  redpajama7b: togethercomputer/RedPajama-INCITE-7B-Chat

# Special models that don't require external APIs
special_models:
  human:
    max_context: 100000
  human_thought:
    max_context: 100000
  replay:
    max_context: 100000
  instant_empty_submit:
    max_context: 100000

# Default values for models when not specified
defaults:
  max_context: 32768
  cost_per_input_token: 0.0  # Default to free for turn-based evaluation
  cost_per_output_token: 0.0  # Default to free for turn-based evaluation
  max_tokens: 4096 